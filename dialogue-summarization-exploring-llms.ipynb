{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-30T10:08:38.983465Z","iopub.status.busy":"2024-01-30T10:08:38.983079Z","iopub.status.idle":"2024-01-30T10:09:06.180480Z","shell.execute_reply":"2024-01-30T10:09:06.179121Z","shell.execute_reply.started":"2024-01-30T10:08:38.983430Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import evaluate\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, BitsAndBytesConfig\n","from datasets import Dataset\n","from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training, PromptEmbedding, PromptTuningConfig\n","import torch\n","# trl: Transformer Reinforcement Learning library\n","from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n","from trl import create_reference_model\n","from trl.core import LengthSampler"]},{"cell_type":"markdown","metadata":{},"source":["# I. Samsum dialogue dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:06.183329Z","iopub.status.busy":"2024-01-30T10:09:06.182421Z","iopub.status.idle":"2024-01-30T10:09:06.666251Z","shell.execute_reply":"2024-01-30T10:09:06.664869Z","shell.execute_reply.started":"2024-01-30T10:09:06.183285Z"},"trusted":true},"outputs":[],"source":["train_data = pd.read_csv('samsum-train.csv')\n","validation_data = pd.read_csv('samsum-validation.csv')\n","test_data = pd.read_csv('samsum-test.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:06.670453Z","iopub.status.busy":"2024-01-30T10:09:06.669939Z","iopub.status.idle":"2024-01-30T10:09:06.678518Z","shell.execute_reply":"2024-01-30T10:09:06.676525Z","shell.execute_reply.started":"2024-01-30T10:09:06.670405Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train shape: (14732, 3)\n","Validation shape: (818, 3)\n","Test shape: (819, 3)\n"]}],"source":["print('Train shape:', train_data.shape)\n","print('Validation shape:', validation_data.shape)\n","print('Test shape:', test_data.shape)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:06.681390Z","iopub.status.busy":"2024-01-30T10:09:06.680658Z","iopub.status.idle":"2024-01-30T10:09:06.780280Z","shell.execute_reply":"2024-01-30T10:09:06.779005Z","shell.execute_reply.started":"2024-01-30T10:09:06.681342Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>dialogue</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>14732</td>\n","      <td>14731</td>\n","      <td>14732</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>14732</td>\n","      <td>14264</td>\n","      <td>14730</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>13818513</td>\n","      <td>Jimmy: Hey, guess what? My car's completely ka...</td>\n","      <td>Seth's pet Oreo that he got when he was 10 is ...</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              id                                           dialogue  \\\n","count      14732                                              14731   \n","unique     14732                                              14264   \n","top     13818513  Jimmy: Hey, guess what? My car's completely ka...   \n","freq           1                                                  4   \n","\n","                                                  summary  \n","count                                               14732  \n","unique                                              14730  \n","top     Seth's pet Oreo that he got when he was 10 is ...  \n","freq                                                    2  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_data.describe()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>dialogue</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>818</td>\n","      <td>818</td>\n","      <td>818</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>818</td>\n","      <td>818</td>\n","      <td>818</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>13817023</td>\n","      <td>A: Hi Tom, are you busy tomorrow’s afternoon?\\...</td>\n","      <td>A will go to the animal shelter tomorrow to ge...</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              id                                           dialogue  \\\n","count        818                                                818   \n","unique       818                                                818   \n","top     13817023  A: Hi Tom, are you busy tomorrow’s afternoon?\\...   \n","freq           1                                                  1   \n","\n","                                                  summary  \n","count                                                 818  \n","unique                                                818  \n","top     A will go to the animal shelter tomorrow to ge...  \n","freq                                                    1  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["validation_data.describe()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>dialogue</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>819</td>\n","      <td>819</td>\n","      <td>819</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>819</td>\n","      <td>819</td>\n","      <td>819</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>13862856</td>\n","      <td>Hannah: Hey, do you have Betty's number?\\nAman...</td>\n","      <td>Hannah needs Betty's number but Amanda doesn't...</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              id                                           dialogue  \\\n","count        819                                                819   \n","unique       819                                                819   \n","top     13862856  Hannah: Hey, do you have Betty's number?\\nAman...   \n","freq           1                                                  1   \n","\n","                                                  summary  \n","count                                                 819  \n","unique                                                819  \n","top     Hannah needs Betty's number but Amanda doesn't...  \n","freq                                                    1  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["test_data.describe()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:06.782148Z","iopub.status.busy":"2024-01-30T10:09:06.781684Z","iopub.status.idle":"2024-01-30T10:09:06.790781Z","shell.execute_reply":"2024-01-30T10:09:06.789531Z","shell.execute_reply.started":"2024-01-30T10:09:06.782106Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------\n","Dialogue\n","--------------------------------------------------\n","Amanda: I baked  cookies. Do you want some?\n","Jerry: Sure!\n","Amanda: I'll bring you tomorrow :-)\n","--------------------------------------------------\n","Summary\n","--------------------------------------------------\n","Amanda baked cookies and will bring Jerry some tomorrow.\n"]}],"source":["print('-'*50)\n","print(f'Dialogue')\n","print('-'*50)\n","print(train_data.iloc[0]['dialogue'])\n","print('-'*50)\n","print('Summary')\n","print('-'*50)\n","print(train_data.iloc[0]['summary'])"]},{"cell_type":"markdown","metadata":{},"source":["# II. Load model"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:06.793556Z","iopub.status.busy":"2024-01-30T10:09:06.793039Z","iopub.status.idle":"2024-01-30T10:09:09.911840Z","shell.execute_reply":"2024-01-30T10:09:09.910107Z","shell.execute_reply.started":"2024-01-30T10:09:06.793512Z"},"trusted":true},"outputs":[],"source":["model_name = 'google/flan-t5-small'\n","reference_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:09.914146Z","iopub.status.busy":"2024-01-30T10:09:09.913730Z","iopub.status.idle":"2024-01-30T10:09:11.685763Z","shell.execute_reply":"2024-01-30T10:09:11.684520Z","shell.execute_reply.started":"2024-01-30T10:09:09.914113Z"},"trusted":true},"outputs":[],"source":["# tokenizer to encode and decode text\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:11.688203Z","iopub.status.busy":"2024-01-30T10:09:11.687783Z","iopub.status.idle":"2024-01-30T10:09:11.798689Z","shell.execute_reply":"2024-01-30T10:09:11.797357Z","shell.execute_reply.started":"2024-01-30T10:09:11.688168Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Original text: Hello my name is Blavo\n","Encoded text: tf.Tensor([8774   82  564   19 6942 1621    1], shape=(7,), dtype=int32)\n","Decoded text: Hello my name is Blavo\n"]}],"source":["# test the tokenizer on sample text\n","sample_text = 'Hello my name is Blavo'\n","encoded_text = tokenizer(sample_text, return_tensors='tf')['input_ids'][0]\n","decoded_text = tokenizer.decode(\n","        encoded_text, \n","        skip_special_tokens=True\n","    )\n","print('Original text:', sample_text)\n","print('Encoded text:', encoded_text)\n","print('Decoded text:', decoded_text)"]},{"cell_type":"markdown","metadata":{},"source":["# III. Some text sumarization to see how the base original model is performing"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:11.806271Z","iopub.status.busy":"2024-01-30T10:09:11.805577Z","iopub.status.idle":"2024-01-30T10:09:12.710757Z","shell.execute_reply":"2024-01-30T10:09:12.709573Z","shell.execute_reply.started":"2024-01-30T10:09:11.806229Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------\n","Example 1\n","--------------------------------------------------\n","Eric: MACHINE!\n","Rob: That's so gr8!\n","Eric: I know! And shows how Americans see Russian ;)\n","Rob: And it's really funny!\n","Eric: I know! I especially like the train part!\n","Rob: Hahaha! No one talks to the machine like that!\n","Eric: Is this his only stand-up?\n","Rob: Idk. I'll check.\n","Eric: Sure.\n","Rob: Turns out no! There are some of his stand-ups on youtube.\n","Eric: Gr8! I'll watch them now!\n","Rob: Me too!\n","Eric: MACHINE!\n","Rob: MACHINE!\n","Eric: TTYL?\n","Rob: Sure :)\n","Human summary: Eric and Rob are going to watch a stand-up on youtube.\n","Model summary: Rob will watch some stand-ups on YouTube.\n","--------------------------------------------------\n","Example 2\n","--------------------------------------------------\n","Wanda: Let's make a party!\n","Gina: Why?\n","Wanda: beacuse. I want some fun!\n","Gina: ok, what do u need?\n","Wanda: 1st I need too make a list\n","Gina: noted and then?\n","Wanda: well, could u take yours father car and go do groceries with me?\n","Gina: don't know if he'll agree\n","Wanda: I know, but u can ask :)\n","Gina: I'll try but theres no promisess\n","Wanda: I know, u r the best!\n","Gina: When u wanna go\n","Wanda: Friday?\n","Gina: ok, I'll ask\n","Human summary: Wanda wants to throw a party. She asks Gina to borrow her father's car and go do groceries together. They set the date for Friday. \n","Model summary: Wanda and Gina will make a party on Friday.\n"]}],"source":["indices = [1, 10]\n","for i, index in enumerate(indices):\n","    dialogue = test_data.iloc[index]['dialogue']\n","    summary = test_data.iloc[index]['summary']\n","    inputs = tokenizer(dialogue, return_tensors='pt')['input_ids']\n","    output = tokenizer.decode(\n","        reference_model.generate(\n","            inputs, \n","            max_new_tokens=50,\n","        )[0], \n","        skip_special_tokens=True\n","    )\n","    print('-'*50)\n","    print(f'Example {i+1}')\n","    print('-'*50)\n","    print(dialogue)\n","    print('Human summary:', summary)\n","    print('Model summary:', output)"]},{"cell_type":"markdown","metadata":{},"source":["# IV. In-context learning"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:12.713421Z","iopub.status.busy":"2024-01-30T10:09:12.712639Z","iopub.status.idle":"2024-01-30T10:09:12.722134Z","shell.execute_reply":"2024-01-30T10:09:12.720796Z","shell.execute_reply.started":"2024-01-30T10:09:12.713376Z"},"trusted":true},"outputs":[],"source":["def make_prompt(example_indices, index_to_summarize):\n","    prompt = ''\n","    for index in example_indices:\n","        dialogue = test_data.iloc[index]['dialogue']\n","        summary = test_data.iloc[index]['summary']\n","        prompt += f\"\"\"\n","        Dialogue:\n","        {dialogue}\n","        what is going on?\n","        {summary}\n","        \"\"\"\n","    dialogue = test_data.iloc[index_to_summarize]['dialogue']\n","    prompt += f\"\"\"\n","    Dialogue:\n","    {dialogue}\n","    What is going on?\n","    \"\"\" \n","    return prompt"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Zero shot inference with prompt template"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:12.724766Z","iopub.status.busy":"2024-01-30T10:09:12.724304Z","iopub.status.idle":"2024-01-30T10:09:12.735341Z","shell.execute_reply":"2024-01-30T10:09:12.733870Z","shell.execute_reply.started":"2024-01-30T10:09:12.724724Z"},"trusted":true},"outputs":[],"source":["def in_context_learning(indices, index):\n","    zero_shot_prompt = make_prompt(indices, index)\n","    inputs = tokenizer(zero_shot_prompt, return_tensors='pt')['input_ids']\n","    human_summary = test_data.iloc[index]['summary']\n","    output = tokenizer.decode(\n","        reference_model.generate(\n","            inputs, \n","            max_new_tokens=50,\n","        )[0], \n","        skip_special_tokens=True\n","    )\n","    print('Human sumary:', human_summary)\n","    print('Model summary:', output)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:12.737781Z","iopub.status.busy":"2024-01-30T10:09:12.736890Z","iopub.status.idle":"2024-01-30T10:09:13.154860Z","shell.execute_reply":"2024-01-30T10:09:13.153666Z","shell.execute_reply.started":"2024-01-30T10:09:12.737740Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Human sumary: Wanda wants to throw a party. She asks Gina to borrow her father's car and go do groceries together. They set the date for Friday. \n","Model summary: Wanda and Gina will make a party on Friday.\n"]}],"source":["in_context_learning([], 10)"]},{"cell_type":"markdown","metadata":{},"source":["## 2. One shot inference with template prompt"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:13.158571Z","iopub.status.busy":"2024-01-30T10:09:13.156747Z","iopub.status.idle":"2024-01-30T10:09:14.610711Z","shell.execute_reply":"2024-01-30T10:09:14.609490Z","shell.execute_reply.started":"2024-01-30T10:09:13.158521Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Human sumary: Wanda wants to throw a party. She asks Gina to borrow her father's car and go do groceries together. They set the date for Friday. \n","Model summary: Wanda and Gina will make a party on Friday.\n"]}],"source":["in_context_learning([3], 10)"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Few shot inference with template prompt"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:14.613593Z","iopub.status.busy":"2024-01-30T10:09:14.612724Z","iopub.status.idle":"2024-01-30T10:09:16.334496Z","shell.execute_reply":"2024-01-30T10:09:16.331778Z","shell.execute_reply.started":"2024-01-30T10:09:14.613536Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n"]},{"name":"stdout","output_type":"stream","text":["Human sumary: Wanda wants to throw a party. She asks Gina to borrow her father's car and go do groceries together. They set the date for Friday. \n","Model summary: Wanda and Gina will make a party on Friday.\n"]}],"source":["in_context_learning([6, 1], 10)"]},{"cell_type":"markdown","metadata":{},"source":["# V. Fine-tuning of the FLAN-T5 model on the samsum dataset "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:16.336961Z","iopub.status.busy":"2024-01-30T10:09:16.336498Z","iopub.status.idle":"2024-01-30T10:09:17.926535Z","shell.execute_reply":"2024-01-30T10:09:17.925102Z","shell.execute_reply.started":"2024-01-30T10:09:16.336916Z"},"trusted":true},"outputs":[],"source":["# evaluate predictions\n","rouge = evaluate.load(\"rouge\")\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","\n","    return {k: round(v, 4) for k, v in result.items()}\n","\n","# Display the total number of parameters and the number of trainable parameters\n","def print_number_of_trainable_model_parameters(model):\n","    trainable_model_params = 0\n","    all_model_params = 0\n","    for _, param in model.named_parameters():\n","        all_model_params += param.numel()\n","        if param.requires_grad:\n","            trainable_model_params += param.numel()\n","    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n","\n","# tokenize the dataset\n","def tokenize_dataset(data):\n","    start_prompt = \"Summarize the following conversation. \\n\\n\"\n","    end_prompt = \"\\n\\nSummary: \"\n","    inputs = [start_prompt + str(dialogue) + end_prompt for dialogue in data[\"dialogue\"]]\n","    data['input_ids'] = tokenizer(inputs, padding=\"max_length\", truncation=True).input_ids\n","\n","    labels = tokenizer(text_target=data[\"summary\"], padding=\"max_length\", truncation=True)\n","\n","    data[\"labels\"] = labels[\"input_ids\"]\n","    return data"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:17.932027Z","iopub.status.busy":"2024-01-30T10:09:17.931506Z","iopub.status.idle":"2024-01-30T10:09:17.946594Z","shell.execute_reply":"2024-01-30T10:09:17.943803Z","shell.execute_reply.started":"2024-01-30T10:09:17.931981Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------\n","Reference model\n","--------------------------------------------------\n","trainable model parameters: 76961152\n","all model parameters: 76961152\n","percentage of trainable model parameters: 100.00%\n"]}],"source":["print('-'*50)\n","print('Reference model')\n","print('-'*50)\n","print(print_number_of_trainable_model_parameters(reference_model))"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:17.955531Z","iopub.status.busy":"2024-01-30T10:09:17.954728Z","iopub.status.idle":"2024-01-30T10:09:18.050806Z","shell.execute_reply":"2024-01-30T10:09:18.049372Z","shell.execute_reply.started":"2024-01-30T10:09:17.955482Z"},"trusted":true},"outputs":[],"source":["# convert to huggingface Dataset\n","train_data = Dataset.from_pandas(train_data)\n","validation_data = Dataset.from_pandas(validation_data)\n","test_data = Dataset.from_pandas(test_data)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:18.053447Z","iopub.status.busy":"2024-01-30T10:09:18.052906Z","iopub.status.idle":"2024-01-30T10:09:28.816653Z","shell.execute_reply":"2024-01-30T10:09:28.815356Z","shell.execute_reply.started":"2024-01-30T10:09:18.053401Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4a71476a0b2442b9b01ece46ba63345","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b3cd7252c84423d93be33b637551be2","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/818 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"805426d6c3984cd0a5c573d06cbf354a","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# tokenize the dataset\n","tokenized_train_data = train_data.map(tokenize_dataset, batched=True)\n","tokenized_validation_data = validation_data.map(tokenize_dataset, batched=True)\n","tokenized_test_data = test_data.map(tokenize_dataset, batched=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:28.819127Z","iopub.status.busy":"2024-01-30T10:09:28.818598Z","iopub.status.idle":"2024-01-30T10:09:28.834106Z","shell.execute_reply":"2024-01-30T10:09:28.832451Z","shell.execute_reply.started":"2024-01-30T10:09:28.819090Z"},"trusted":true},"outputs":[],"source":["tokenized_train_data = tokenized_train_data.remove_columns(['id', 'dialogue', 'summary'])\n","tokenized_validation_data = tokenized_validation_data.remove_columns(['id', 'dialogue', 'summary'])\n","tokenized_test_data = tokenized_test_data.remove_columns(['id', 'dialogue', 'summary'])"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["tokenized_train_data.set_format(type='torch')\n","tokenized_validation_data.set_format(type='torch')\n","tokenized_test_data.set_format(type='torch')"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Fine-tune by unfreezing some layers of the reference model"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:28.836779Z","iopub.status.busy":"2024-01-30T10:09:28.835678Z","iopub.status.idle":"2024-01-30T10:09:28.872956Z","shell.execute_reply":"2024-01-30T10:09:28.871348Z","shell.execute_reply.started":"2024-01-30T10:09:28.836736Z"},"trusted":true},"outputs":[],"source":["selective_model = reference_model\n","\n","# freeze all weights\n","for param in selective_model.parameters():\n","    param.requires_grad=False"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:28.875103Z","iopub.status.busy":"2024-01-30T10:09:28.874707Z","iopub.status.idle":"2024-01-30T10:09:28.887088Z","shell.execute_reply":"2024-01-30T10:09:28.885724Z","shell.execute_reply.started":"2024-01-30T10:09:28.875069Z"},"trusted":true},"outputs":[],"source":["# Unfreeze the weights of the last decoder layer\n","for param in selective_model.decoder.block[-1].layer[-1].layer_norm.parameters():\n","    param.requires_grad = True"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:28.889325Z","iopub.status.busy":"2024-01-30T10:09:28.888891Z","iopub.status.idle":"2024-01-30T10:09:28.903470Z","shell.execute_reply":"2024-01-30T10:09:28.902050Z","shell.execute_reply.started":"2024-01-30T10:09:28.889290Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------\n","Selective model\n","--------------------------------------------------\n","trainable model parameters: 512\n","all model parameters: 76961152\n","percentage of trainable model parameters: 0.00%\n"]}],"source":["print('-'*50)\n","print('Selective model')\n","print('-'*50)\n","print(print_number_of_trainable_model_parameters(selective_model))"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:28.906194Z","iopub.status.busy":"2024-01-30T10:09:28.905674Z","iopub.status.idle":"2024-01-30T10:09:29.882283Z","shell.execute_reply":"2024-01-30T10:09:29.880788Z","shell.execute_reply.started":"2024-01-30T10:09:28.906147Z"},"trusted":true},"outputs":[],"source":["\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"dialogue-summary-training-selective-fine-tuning\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    weight_decay=0.01,\n","    num_train_epochs=1,\n","    logging_steps=1,\n","    max_steps=1\n",")\n","\n","selective_trainer = Seq2SeqTrainer(\n","    model=selective_model,\n","    args=training_args,\n","    train_dataset=tokenized_train_data,\n","    eval_dataset=tokenized_validation_data,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:09:46.722031Z","iopub.status.busy":"2024-01-30T10:09:46.720848Z","iopub.status.idle":"2024-01-30T10:09:46.727161Z","shell.execute_reply":"2024-01-30T10:09:46.725721Z","shell.execute_reply.started":"2024-01-30T10:09:46.721947Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27fbb3a96911416bb14216d9356ea885","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'loss': 62.0058, 'learning_rate': 0.0, 'epoch': 0.0}\n","{'train_runtime': 176.4862, 'train_samples_per_second': 0.181, 'train_steps_per_second': 0.006, 'train_loss': 62.005760192871094, 'epoch': 0.0}\n"]},{"data":{"text/plain":["TrainOutput(global_step=1, training_loss=62.005760192871094, metrics={'train_runtime': 176.4862, 'train_samples_per_second': 0.181, 'train_steps_per_second': 0.006, 'train_loss': 62.005760192871094, 'epoch': 0.0})"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["selective_trainer.train()"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["('./selective-dialogue-summary-checkpoint-local\\\\tokenizer_config.json',\n"," './selective-dialogue-summary-checkpoint-local\\\\special_tokens_map.json',\n"," './selective-dialogue-summary-checkpoint-local\\\\tokenizer.json')"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["selective_model_path=\"./selective-dialogue-summary-checkpoint-local\"\n","\n","selective_trainer.model.save_pretrained(selective_model_path)\n","tokenizer.save_pretrained(selective_model_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 2. PEFT"]},{"cell_type":"markdown","metadata":{},"source":["### Quantize the model"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n",")"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["quantized_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, quantization_config=config)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["# preprocess the quantized model for training\n","quantized_model = prepare_model_for_kbit_training(quantized_model, config)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["'trainable model parameters: 0\\nall model parameters: 76961152\\npercentage of trainable model parameters: 0.00%'"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["print_number_of_trainable_model_parameters(quantized_model)"]},{"cell_type":"markdown","metadata":{},"source":["### 1. LoRA"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:19:24.780555Z","iopub.status.busy":"2024-01-30T10:19:24.780110Z","iopub.status.idle":"2024-01-30T10:19:24.787786Z","shell.execute_reply":"2024-01-30T10:19:24.786169Z","shell.execute_reply.started":"2024-01-30T10:19:24.780515Z"},"trusted":true},"outputs":[],"source":["lora_config = LoraConfig(\n","    r=4, # Rank\n","    lora_alpha=32,\n","    target_modules=[\"q\", \"v\"],\n","    lora_dropout=0.1,\n","    bias=\"none\",\n","    task_type=TaskType.SEQ_2_SEQ_LM\n",")"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:19:27.172399Z","iopub.status.busy":"2024-01-30T10:19:27.172008Z","iopub.status.idle":"2024-01-30T10:19:27.779270Z","shell.execute_reply":"2024-01-30T10:19:27.778340Z","shell.execute_reply.started":"2024-01-30T10:19:27.172369Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable model parameters: 172032\n","all model parameters: 77133184\n","percentage of trainable model parameters: 0.22%\n"]}],"source":["original_model = quantized_model\n","peft_model = get_peft_model(original_model, \n","                            lora_config)\n","print(print_number_of_trainable_model_parameters(peft_model))"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:19:53.355759Z","iopub.status.busy":"2024-01-30T10:19:53.355354Z","iopub.status.idle":"2024-01-30T10:19:53.378765Z","shell.execute_reply":"2024-01-30T10:19:53.377502Z","shell.execute_reply.started":"2024-01-30T10:19:53.355727Z"},"trusted":true},"outputs":[],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"dialogue-summary-training-peft-LoRA-fine-tuning\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    weight_decay=0.01,\n","    num_train_epochs=1,\n","    logging_steps=1,\n","    max_steps=1,\n",")\n","\n","peft_lora_trainer = Seq2SeqTrainer(\n","    model=peft_model,\n","    args=training_args,\n","    train_dataset=tokenized_train_data,\n","    eval_dataset=tokenized_validation_data,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T10:19:57.064257Z","iopub.status.busy":"2024-01-30T10:19:57.063833Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44380efe209648e29e56efbc0fa5f272","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'loss': 62.1314, 'learning_rate': 0.0, 'epoch': 0.0}\n","{'train_runtime': 177.7116, 'train_samples_per_second': 0.18, 'train_steps_per_second': 0.006, 'train_loss': 62.13142776489258, 'epoch': 0.0}\n"]},{"data":{"text/plain":["TrainOutput(global_step=1, training_loss=62.13142776489258, metrics={'train_runtime': 177.7116, 'train_samples_per_second': 0.18, 'train_steps_per_second': 0.006, 'train_loss': 62.13142776489258, 'epoch': 0.0})"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["peft_lora_trainer.train()"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["('./peft-lora-dialogue-summary-checkpoint-local\\\\tokenizer_config.json',\n"," './peft-lora-dialogue-summary-checkpoint-local\\\\special_tokens_map.json',\n"," './peft-lora-dialogue-summary-checkpoint-local\\\\tokenizer.json')"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["peft_lora_model_path=\"./peft-lora-dialogue-summary-checkpoint-local\"\n","\n","peft_lora_trainer.model.save_pretrained(peft_lora_model_path)\n","tokenizer.save_pretrained(peft_lora_model_path)"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Prompt tuning"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":true},"outputs":[],"source":["config = PromptTuningConfig(\n","    peft_type=\"PROMPT_TUNING\",\n","    task_type=\"SEQ_2_SEQ_LM\",\n","    num_virtual_tokens=8,\n","    prompt_tuning_init=\"TEXT\",\n","    prompt_tuning_init_text=\"Summarize the following conversation. \\n\\nDialogue: \",\n","    tokenizer_name_or_path=model_name,\n",")"]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[],"source":["peft_reference_model = quantized_model\n","peft_prompt_tuning = get_peft_model(peft_reference_model, config)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable model parameters: 8192\n","all model parameters: 76969344\n","percentage of trainable model parameters: 0.01%\n"]}],"source":["print(print_number_of_trainable_model_parameters(peft_prompt_tuning))"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"dialogue-summary-training-peft-prompt-tuning\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    weight_decay=0.01,\n","    num_train_epochs=1,\n","    logging_steps=1,\n","    max_steps=1,\n",")\n","\n","peft_prompt_tuning_trainer = Seq2SeqTrainer(\n","    model=peft_prompt_tuning,\n","    args=training_args,\n","    train_dataset=tokenized_train_data,\n","    eval_dataset=tokenized_validation_data,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9a4552232514b01a3a9ac7afb748f7f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'loss': 61.8854, 'learning_rate': 0.0, 'epoch': 0.0}\n","{'train_runtime': 147.6886, 'train_samples_per_second': 0.217, 'train_steps_per_second': 0.007, 'train_loss': 61.88544845581055, 'epoch': 0.0}\n"]},{"data":{"text/plain":["TrainOutput(global_step=1, training_loss=61.88544845581055, metrics={'train_runtime': 147.6886, 'train_samples_per_second': 0.217, 'train_steps_per_second': 0.007, 'train_loss': 61.88544845581055, 'epoch': 0.0})"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["peft_prompt_tuning_trainer.train()"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:09:45.654321Z","iopub.status.idle":"2024-01-30T10:09:45.654788Z","shell.execute_reply":"2024-01-30T10:09:45.654597Z","shell.execute_reply.started":"2024-01-30T10:09:45.654576Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('./peft-prompt_tuning-dialogue-summary-checkpoint-local\\\\tokenizer_config.json',\n"," './peft-prompt_tuning-dialogue-summary-checkpoint-local\\\\special_tokens_map.json',\n"," './peft-prompt_tuning-dialogue-summary-checkpoint-local\\\\tokenizer.json')"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["peft_prompt_tuning_model_path=\"./peft-prompt_tuning-dialogue-summary-checkpoint-local\"\n","\n","peft_prompt_tuning_trainer.model.save_pretrained(peft_prompt_tuning_model_path)\n","tokenizer.save_pretrained(peft_prompt_tuning_model_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 3. RLHF (Reinforcement learning with Human Feedback)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:09:45.655904Z","iopub.status.idle":"2024-01-30T10:09:45.656384Z","shell.execute_reply":"2024-01-30T10:09:45.656195Z","shell.execute_reply.started":"2024-01-30T10:09:45.656175Z"},"trusted":true},"outputs":[],"source":["# optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n","# reference_model.compile(optimizer=optimizer)  \n","# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=validation_dataset)\n","# callbacks = [metric_callback]\n","# # create a tensorflow dataset\n","# train_dataset = tf.data.Dataset.from_tensor_slices((tokenized_train_data['input_ids'], tokenized_train_data['labels']))\n","# validation_dataset = tf.data.Dataset.from_tensor_slices((tokenized_validation_data['input_ids'], tokenized_validation_data['labels']))\n","\n","# train_dataset = train_dataset.batch(32).shuffle(buffer_size=1000).prefetch(tf.data.AUTOTUNE)\n","# validation_dataset = validation_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3438844,"sourceId":6004344,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
